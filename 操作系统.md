# 操作系统

[TOC]

##### 经典同步问题：

1. 哲学家就餐问题

   ![image-20250405092755843](img/image-20250405092755843.png)

2. 读者写者问题

   ![image-20250405092836299](img/image-20250405092836299.png)

3. 死锁 是指两个或多个进程在运行过程中，因争夺资源而陷入相互等待的状态，导致它们无法继续执行，系统无法正常推进。、

   示例：

   进程A持有资源1，请求资源2；
   进程B持有资源2，请求资源1；
   两者互不相让，形成僵局。

   ---------------------------------
   死锁的四个必要条件：
   互斥（Mutual Exclusion）

   资源一次只能被一个进程独占使用（如打印机）。

   

   占有且等待（Hold and Wait）

   进程已持有至少一个资源，同时等待其他进程释放额外资源。

   

   不可抢占（No Preemption）

   资源不能被强制从持有它的进程中剥夺，只能自愿释放。

   

   循环等待（Circular Wait）

   存在进程资源的环形等待链（如A→B→C→A）。

4. ##### 悲观锁与乐观锁的区别，就像“防贼”和“事后检查”两种生活态度：

   悲观锁（Pessimistic Lock）——出门必锁门
   核心思想：“总有人会改我的数据，先锁住再说！”
   工作方式：操作数据前先加锁（如行锁、表锁），确保独占访问。
   适用场景：
   写操作频繁，冲突概率高（如银行转账、库存扣减）。
   长事务或复杂业务逻辑（需长时间持有数据）。
   优点：保证强一致性，避免脏写。
   缺点：加锁时间长，降低并发性能（其他线程需等待）。

   乐观锁（Optimistic Lock）——回家再检查
   核心思想：“大家一般不会冲突，万一冲突了再处理！”
   工作方式：不加锁，提交时检查数据是否被修改（如版本号、时间戳）。
   适用场景：
   读多写少，冲突概率低（如文章点赞、配置更新）。

   ##### 高并发读场景（避免锁竞争拖慢系统）。

   1：电商秒杀
   悲观锁：用户点击秒杀时，直接锁库存 → 可能拖垮数据库。
   乐观锁：先放用户进入，提交订单时检查库存版本号 → 更适合高并发。
   场景2：文档协作编辑
   悲观锁：编辑前锁定文档 → 其他人无法同时修改，体验差。
   乐观锁：所有人自由编辑，保存时检查版本冲突 → 类似Google Docs。

   ##### 如何选择？

   选悲观锁：
   数据强一致性要求高（如金融系统）。
   写冲突频繁，重试成本高。
   选乐观锁：
   读多写少，冲突概率低。
   系统吞吐量要求高（如互联网应用）。

5. ##### 线程上下文切换是指：

   ##### 线程的上下文切换的是什么？当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

6. ##### 自旋锁

   自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。

   自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系。

   **自旋锁** 就像你在餐厅门口等位时，**一直盯着服务员问“有空位了吗？”**，而不是取个号去逛街。用大白话解释：

   ------

   ##### **自旋锁是啥？**

   - **核心逻辑**：线程在抢不到锁时，**死循环不停检查锁状态**，直到锁被释放。
   - 特点：
     - **不放弃CPU**：线程一直占着CPU，不睡觉（不进入阻塞状态）。
     - **适合短等待**：如果锁很快被释放，能立即抢到，响应快。

   ##### **自旋锁 vs 互斥锁（普通锁）**

   |   **场景**   |         **自旋锁**          |          **互斥锁**          |
   | :----------: | :-------------------------: | :--------------------------: |
   | **等锁方式** |   死循环问“锁释放了吗？”    | 取个号去睡觉，等锁释放被叫醒 |
   | **CPU占用**  |     高（一直占着CPU问）     |      低（睡觉不占CPU）       |
   | **适用场景** | 锁持有时间极短（如几纳秒）  | 锁持有时间长（如几毫秒以上） |
   | **典型应用** | 内核中断处理、多核CPU短任务 |     用户态程序、文件读写     |

   ------

   #####  举个栗子🌰——抢厕所

   - **自旋锁**：
     你急着上厕所，门锁着。你站在门口 **不停敲门**：“好了没？好了没？” → 里面的人一出来，你立刻冲进去。
     - **优点**：反应快，一开门就能抢到。
     - **缺点**：一直敲门累死自己（浪费体力/CPU）。
   - **互斥锁**：
     你发现厕所门锁着，**回工位刷手机**，等有人喊“厕所空了”再过去。
     - **优点**：省体力（不占CPU）。
     - **缺点**：可能错过第一时间（唤醒延迟）。

   ------

   ##### **自旋锁的适用场景**

   - **锁持有时间极短**：比如修改一个变量值、更新计数器。
   - **多核CPU环境**：一个核死循环等锁，其他核照常干活，不影响整体效率。
   - **不能睡眠的场景**：如操作系统内核的中断处理程序（中断时不能切换线程）。

   ------

   ##### **自旋锁的坑**

   - **单核CPU慎用**：如果锁一直被占用，自旋锁会 **100%占着CPU**，导致其他线程无法运行，永远拿不到锁（死锁）。
   - **长时间等待血亏**：自旋锁等1秒 → CPU空转1秒，不如让出CPU给其他任务。

7. ##### 加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。

   **锁** 就像现实生活中的 **“门锁”**，只不过它保护的不是房间，而是计算机中的 **共享资源（比如变量、文件、数据库记录）**，防止多个线程或进程同时修改导致数据混乱。

   - **本质**：一种同步工具，确保 **同一时间只有一个线程能访问共享资源**。
   - 类比：
     - 公共厕所只有一个坑位，进去的人锁门（加锁），出来解锁（释放锁），其他人才能用。
     - 多人编辑同一份文档，谁先打开就锁定文件，其他人只能等。

   ##### **避免结果不可预测**

   - 场景

     ：多人抢票系统，余票为1时，两个用户同时点击购买。

     - **不加锁**：可能两人都买到票，导致超卖。
     - **加锁**：第一个人锁定票数，第二个人需等待，确保余票正确扣减。

   ##### **锁的工作流程**

   1. 加锁：线程访问共享资源前，先申请锁。
      - 如果锁空闲 → 获得锁，进入临界区（需要保护的代码段）。
      - 如果锁被占用 → 等待（阻塞或自旋）。
   2. **操作资源**：在锁的保护下安全修改数据。
   3. **释放锁**：操作完成后释放锁，其他线程可竞争获取。

   ------

   ##### **锁的代价**

   - **性能开销**：加锁/解锁需要时间，高并发时可能成为瓶颈。
   - **死锁风险**：多个锁互相等待（如A等B，B等A）。
   - **设计复杂度**：锁粒度太粗（性能差）、太细（易出错）。

   ------

   ##### **常见锁的类型**

   |  **锁类型**  |     **特点**      |     **适用场景**     |
   | :----------: | :---------------: | :------------------: |
   |  **互斥锁**  | 阻塞等待，让出CPU |   大部分用户态程序   |
   |  **自旋锁**  | 忙等待，不释放CPU | 内核短操作、多核环境 |
   |  **读写锁**  |  读共享，写独占   |  读多写少（如缓存）  |
   | **条件变量** | 等待特定条件成立  |  生产者-消费者模型   |

   ------

   ##### **总结**

   - **锁是并发编程的“交通警察”**：确保共享资源有序访问。
   - 核心口诀：
     - 共享数据要保护，先加锁来后操作；

8. 开发过程中，最常见的就是互斥锁的了，互斥锁加锁失败时，会用「线程切换」来应对，当加锁失败的线程再次加锁成功后的这一过程，会有两次线程上下文切换的成本，性能损耗比较大。

   如果我们明确知道被锁住的代码的执行时间很短，那我们应该选择开销比较小的自旋锁，因为自旋锁加锁失败时，并不会主动产生线程切换，而是一直忙等待，直到获取到锁，那么如果被锁住的代码执行时间很短，那这个忙等待的时间相对应也很短。

   如果能区分读操作和写操作的场景，那读写锁就更合适了，它允许多个读线程可以同时持有读锁，提高了读的并发性。根据偏袒读方还是写方，可以分为读优先锁和写优先锁，读优先锁并发性很强，但是写线程会被饿死，而写优先锁会优先服务写线程，读线程也可能会被饿死，那为了避免饥饿的问题，于是就有了公平读写锁，它是用队列把请求锁的线程排队，并保证先入先出的原则来对线程加锁，这样便保证了某种线程不会被饿死，通用性也更好点。

   互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。

   另外，互斥锁、自旋锁、读写锁都属于悲观锁，悲观锁认为并发访问共享资源时，冲突概率可能非常高，所以在访问共享资源前，都需要先加锁。

   相反的，如果并发访问共享资源时，冲突概率非常低的话，就可以使用乐观锁，它的工作方式是，在访问共享资源时，不用先加锁，修改完共享资源后，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。

   但是，一旦冲突概率上升，就不适合使用乐观锁了，因为它解决冲突的重试成本非常高。

   不管使用的哪种锁，我们的加锁的代码范围应该尽可能的小，也就是加锁的粒度要小，这样执行速度会比较快。再来，使用上了合适的锁，就会快上加快了。

   ------

   ## 五、调度算法

   ### 进程调度/页面置换/磁盘调度算法

   ------

   ## 1、进程调度

   **进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。**
   
   **当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。**
   
   什么时候会发生 CPU 调度呢？通常有以下情况：
   
   1. 当进程从运行状态转到等待状态；
   
   2. 当进程从运行状态转到就绪状态；
   
   3. 当进程从等待状态转到就绪状态；
   
   4. 当进程从运行状态转到终止状态；
   
      其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。
   
      非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。
   
      而抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。
   
      你可能会好奇为什么第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。
   
      那第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。
   
   **调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。**
   
   **调度算法影响的是进程的等待时间，而无法改变进程实际需要的 CPU 时间和 I/O 时间。** 这句话可以拆解为以下核心点：
   
   ---
   
   ### **1. 什么是“等待时间”？**
   - **定义**：进程在 **就绪队列** 中等待被 CPU 调度的时间总和。  
   - **受调度算法影响**：不同算法决定了进程何时能获得 CPU 使用权。  
     - **例**：短作业优先（SJF）会让短进程少等待，长进程多等待；而先来先服务（FCFS）则按到达顺序排队，不管任务长短。
   
   ---
   
   ### **2. 什么是“进程真在使用 CPU 的时间”和“I/O 时间”？**
   - **CPU 时间**：进程 **实际执行代码** 所需的时间（如计算 1+1、排序数组）。  
     - **由程序逻辑决定**：无论调度算法如何，计算 1 亿次加法总需要固定的 CPU 时间。  
   - **I/O 时间**：进程 **等待外部设备** 的时间（如读取硬盘、网络请求）。  
     - **由硬件速度决定**：无论调度算法如何，从硬盘读 1GB 数据总需要固定的 I/O 时间。
   
   ---
   
   ### **3. 为什么调度算法无法影响 CPU 和 I/O 时间？**
   - **CPU 时间**：  
     - 程序需要执行多少条指令是固定的，调度算法只能决定 **何时分配 CPU**，但无法减少 **总指令数**。  
     - **例**：一个进程需要 10 秒 CPU 时间，无论是连续执行（FCFS）还是分片执行（RR），总时间都是 10 秒。
   
   - **I/O 时间**：  
     - I/O 操作的速度由硬件（如磁盘转速、网络带宽）决定，调度算法只能管理 **I/O 请求的顺序**，但无法加速设备响应。  
     - **例**：从 SSD 读取文件需要 0.1 秒，无论调度算法如何优化，这个时间无法缩短。
   
   ---
   
   ### **4. 调度算法的作用范围**
   | **调度算法能影响的**             | **调度算法不能影响的**         |
   | -------------------------------- | ------------------------------ |
   | 进程在就绪队列中的等待时间       | 进程实际需要的 CPU 时间        |
   | 进程获得 CPU 的顺序和频率        | 进程执行代码的速度（CPU 算力） |
   | 进程切换的开销（上下文切换次数） | I/O 设备的物理速度             |
   | 系统整体的吞吐量和响应时间       | 单个进程的 CPU 或 I/O 需求     |
   
   ---
   
   ### **5. 举个实际例子**
   假设有两个进程：  
   - **进程A**：需要 5 秒 CPU 时间（纯计算任务）。  
   - **进程B**：需要 2 秒 CPU 时间 + 3 秒 I/O 时间。  
   
   **不同调度算法的表现**：  
   - **FCFS（先来先服务）**：  
     - 若 A 先执行 → A 用 5 秒 CPU，B 等待 5 秒后执行 → B 总等待时间 = 5 秒。  
     - **总 CPU 时间**：A(5) + B(2) = 7 秒（不变）。  
     - **总 I/O 时间**：B(3) 秒（不变）。  
   
   - **SJF（短作业优先）**：  
     - 若 B 先执行 → B 用 2 秒 CPU，A 等待 2 秒后执行 → B 总等待时间 = 0 秒，A 总等待时间 = 2 秒。  
     - **总 CPU 时间**：A(5) + B(2) = 7 秒（不变）。  
     - **总 I/O 时间**：B(3) 秒（不变）。  
   
   → **调度算法改变了等待时间，但 CPU 和 I/O 时间始终不变**。
   
   ---
   
   ### **6. 总结**
   - **调度算法是“时间管理大师”**：决定进程何时运行、运行多久，优化等待时间和系统效率。  
   - **程序需求是“硬指标”**：CPU 和 I/O 时间由代码和硬件决定，调度算法无法压缩。  
   - **关键结论**：  
     - 你可以通过调度让任务更快开始，但无法让它更快完成（除非升级硬件或优化代码）。  
     - 想缩短任务总耗时？优化程序逻辑或换更快的硬件，而不是调整调度算法！  
   
   下次遇到性能瓶颈时，先分清是“等太久”还是“干太慢”——调度算法只管前者，不管后者。 ⏳🚀
   
   
   
   **进程调度算法** 就像银行柜员决定 **“下一个叫哪个号”** 的规则，目标是让客户（进程）高效办理业务（执行任务），同时兼顾公平性和响应速度。以下是常见调度算法的大白话解释：
   
   ---
   
   ### **1. 先来先服务（FCFS）——老实人排队**
   - **规则**：谁先来，谁先办，办完一个再下一个。  
   - **优点**：简单公平，不插队。  
   - **缺点**：  
     - **长任务卡死短任务**：比如第一个人办1小时业务，后面的人等崩溃。  
     - **平均等待时间长**：短任务被长任务拖累。  
   - **场景**：早期简单系统，现已少用。
   - FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。
   
   ---
   
   ### **2. 短作业优先（SJF）——VIP快速通道**
   - **规则**：柜员优先处理 **“办理时间最短”** 的业务。  
   - **优点**：平均等待时间最短，短任务爽翻天。  
   - **缺点**：  
     - **长任务饿死**：如果一直来短任务，长任务永远轮不到。  
     - **预知时间难**：现实中很难提前知道业务要办多久。  
   - **场景**：批处理系统（如后台计算任务）。
   - 比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。
   
   
   
   ### 小林：那么，高响应比优先
   
   （\*Highest Response Ratio Next, HRRN\*）调度算法**主要是权衡了短作业和长作业。
   
   
   
   #### **算法核心思想**
   
   - **响应比（Response Ratio）**：动态计算每个作业的优先级，优先调度 **响应比最高** 的作业。
   
     ![image-20250405164232312](img/image-20250405164232312.png)
   
     - **等待时间**：作业在就绪队列中等待的时间。
     - **预计运行时间**：作业需要的 CPU 时间（需提前预知）。
   
   - 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
   - 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；
   
   ---
   
   ### **3. 时间片轮转（RR）——每人限时办业务**
   - **规则**：每人最多办 **固定时间（时间片）**，超时就重新排队。  
     - 比如时间片=5分钟：A办5分钟 → B办5分钟 → C办5分钟 → 循环。  
     
   - **优点**：公平，响应快，适合交互式系统（如电脑桌面）。  
   
   - **缺点**：  
     - 时间片太短 → 频繁切换，效率低。  
     - 时间片太长 → 退化成FCFS，短任务等太久。  
     
   - **场景**：现代操作系统的默认调度策略。
   
     **每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。**
   
   - 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
   - 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；
   
   另外，时间片的长度就是一个很关键的点：
   
   - 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
   - 如果设得太长又可能引起对短作业进程的响应时间变长。将
   
   通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值
   
   ---
   
   ### **4. 优先级调度——看人下菜碟**
   - **规则**：给每个任务设优先级，柜员先处理优先级高的。  
     - **静态优先级**：优先级固定（如VIP客户永远优先）。  
     - **动态优先级**：优先级随时间变化（如等太久的任务自动升优先级）。  
   - **优点**：灵活，可处理紧急任务。  
   - **缺点**：  
     - **低优先级饿死**：高优先级任务源源不断，低优先级永远等不到。  
     - **优先级反转**：低优先级任务占着资源，高优先级干等（需额外机制解决）。  
   - **场景**：实时系统（如航天控制、工业自动化）。
   
   
   
   对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（\*Highest Priority First，HPF\*）调度算法**。
   
   进程的优先级可以分为，静态优先级或动态优先级：
   
   - 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
   - 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。
   
   该算法也有两种处理优先级高的方法，非抢占式和抢占式：
   
   - 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
   - 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。
   
   但是依然有缺点，可能会导致低优先级的进程永远不会运行。
   
   
   
   ---
   
   ### **5. 多级反馈队列（MLFQ）——智能分诊**
   
   **多级反馈队列（\*Multilevel Feedback Queue\*）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。
   
   - **规则**：  
     1. 设置多个优先级队列，新任务进最高级队列。  
     2. 每个队列时间片不同（高级队列时间片短，低级队列时间长）。  
     3. 任务用完时间片未完成 → 降级到下一队列。  
     4. 任务主动让出CPU（如等I/O） → 保持或升级队列。  
     5. 定期重置所有任务到最高队列 → 防饿死。  
   - **优点**：平衡响应时间和吞吐量，兼顾长短任务。  
   - **缺点**：参数调优复杂（队列数量、时间片大小等）。  
   - **场景**：通用操作系统（如Linux、Windows）。
   
   ![image-20250405164825068](img/image-20250405164825068.png)
   
   小林：它是如何工作的：
   
   - 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
   - **新的进程会被放入到第一级队列的末尾**，按**先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾**，以此类推，直至完成；
   - **当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行**；
   
   可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**
   
   ---
   
   ### **总结：如何选算法？**
   | **场景**           | **推荐算法**         | **原因**                   |
   | ------------------ | -------------------- | -------------------------- |
   | 服务器处理批量任务 | 短作业优先（SJF）    | 快速完成短任务，提升吞吐量 |
   | 个人电脑交互操作   | 时间片轮转（RR）     | 公平响应，避免卡顿         |
   | 实时控制系统       | 优先级调度           | 确保紧急任务优先执行       |
   | 通用多任务环境     | 多级反馈队列（MLFQ） | 自适应长短任务，平衡效率   |
   
   ---
   
   **口诀记忆**：  
   
   - 先来先服务老实人，短作业优先快狠准；  
   - 时间片轮转保公平，优先级调度看身份；  
   - 多级反馈最智能，通用系统它称王！  
   
   理解这些算法，就能明白操作系统如何“公平高效”地管理任务啦！ 🖥️⚖️
   
   
   
   ## 2、内存页面置换算法
   
   **当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断**，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：
   
   - 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。
   
   - 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。
   
   - **缺页中断的处理流程**：
   
     ![image-20250405170104127](img/image-20250405170104127.png)
   
   1. 在 CPU 里访问一条 **Load M 指令，然后 CPU 会去找 M 所对应的页表项。**
   2. 如果**该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。**
   3. **操作系统收到了缺页中断，则会执行缺页中断处理函数**，先会查找该页面在磁盘中的页面的位置。
   4. **找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。**
   5. 页面**从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」**。
   6. 最后，**CPU 重新执行导致缺页异常的指令。**
   
   上面所说的过程，第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？
   
   **找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。**
   
   （）
   
   
   
   **内存页面置换算法** 是操作系统中用于管理虚拟内存的关键机制，当物理内存不足时，决定哪些页面应被换出到磁盘，以腾出空间加载新页面。以下是常见算法的详细说明：
   
   ---
   
   ### **一、最佳置换算法（OPT, Optimal Page Replacement）**
   - **原理**：淘汰 **未来最长时间不再被访问** 的页面（理论最优，但无法实现）。  
   - **优点**：缺页率最低，作为其他算法的性能基准。  
   - **缺点**：需预知未来页面访问序列，实际不可行。  
   - **示例**：  
     访问序列：`2, 3, 2, 1, 5, 2, 4, 5, 3`，物理内存3页。  
     - 当需置换时，选择未来最晚出现的页面（如页面1）。  
   
   ---
   
   ### **二、先进先出算法（FIFO, First-In-First-Out）**
   - **原理**：淘汰 **最早进入内存** 的页面。  
   - **实现**：维护一个队列，新页面加入队尾，置换时移除队首页面。  
   - **优点**：实现简单。  
   - **缺点**：  
     - **Belady 异常**：增加物理页框数时，缺页率可能不降反升。  
     - 忽略页面访问频率，可能淘汰常用页面。  
   - **示例**：  
     访问序列：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`，物理内存3页。  
     - 缺页次数：9次（FIFO） vs 7次（LRU）。  
   
   ---
   
   ### **三、最近最少使用算法（LRU, Least Recently Used）**
   - **原理**：淘汰 **最长时间未被访问** 的页面。  
   - **实现**：  
     - **计数器/时间戳**：记录每个页面最后一次访问时间。  
     - **链表**：每次访问页面时将其移到链表头部，淘汰尾部页面。  
   - **优点**：接近OPT性能，缺页率低。  
   - **缺点**：硬件实现复杂（需记录访问时间）。  
   - **示例**：  
     访问序列：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`，物理内存3页。  
     - 缺页次数：7次。  
   
   ---
   
   ### **四、时钟算法（Clock / Second Chance）**
   - **原理**：近似LRU，通过 **环形链表** 和 **访问位（R位）** 管理页面。  
   - **步骤**：  
     1. 页面组织成环形链表，初始访问位R=0。  
     2. 访问页面时，R=1。  
     3. 置换时，指针循环扫描：  
        - 若R=1 → 置R=0，跳过；  
        - 若R=0 → 淘汰该页。  
   - **优点**：开销低，接近LRU性能。  
   - **缺点**：可能淘汰最近使用但R位被清零的页面。  
   - **示例**：  
     访问序列：`1, 2, 3, 4, 1, 2, 5`，物理内存3页。  
     - 缺页次数：5次。  
   
   ---
   
   ### **五、最不常用算法（LFU, Least Frequently Used）**
   - **原理**：淘汰 **访问次数最少** 的页面。  
   - **实现**：为每个页面维护访问计数器，置换时选择计数最小的页面。  
   - **优点**：适合访问模式稳定的场景。  
   - **缺点**：  
     - 历史累计访问次数可能掩盖近期变化。  
     - 计数器溢出问题。  
   - **变种**：**老化算法（Aging）**，定期右移计数器并叠加新访问位。  
   
   ---
   
   ### **六、算法对比与总结**
   | **算法**  | **实现复杂度** | **缺页率** | **硬件支持**  | **适用场景**            |
   | --------- | -------------- | ---------- | ------------- | ----------------------- |
   | **OPT**   | 理论不可实现   | 最低       | 无            | 性能基准                |
   | **FIFO**  | 简单           | 高         | 无            | 简单系统                |
   | **LRU**   | 高             | 低         | 需要（如TLB） | 通用系统                |
   | **Clock** | 中             | 中低       | 需要R位       | 实际操作系统（如Linux） |
   | **LFU**   | 高             | 中         | 需要计数器    | 特定访问模式            |
   
   ---
   
   ### **七、如何选择页面置换算法？**
   1. **追求性能**：LRU或Clock（平衡开销与效率）。  
   2. **硬件支持有限**：Clock算法（仅需访问位）。  
   3. **简单系统**：FIFO（易实现，但需注意Belady异常）。  
   4. **特定访问模式**：LFU（如缓存热点数据）。  
   
   ---
   
   **口诀**：  
   - OPT理论最优，FIFO简单但有坑；  
   - LRU效果好，实现成本高；  
   - Clock折中选，实际系统最爱用！  
   
   理解这些算法，有助于优化内存管理，提升系统整体性能。 🖥️⚡





