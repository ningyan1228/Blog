# 操作系统

[TOC]

##### 经典同步问题：

1. 哲学家就餐问题

   ![image-20250405092755843](img/image-20250405092755843.png)

2. 读者写者问题

   ![image-20250405092836299](img/image-20250405092836299.png)

3. 死锁 是指两个或多个进程在运行过程中，因争夺资源而陷入相互等待的状态，导致它们无法继续执行，系统无法正常推进。、

   示例：

   进程A持有资源1，请求资源2；
   进程B持有资源2，请求资源1；
   两者互不相让，形成僵局。

   ---------------------------------
   死锁的四个必要条件：
   互斥（Mutual Exclusion）

   资源一次只能被一个进程独占使用（如打印机）。

   

   占有且等待（Hold and Wait）

   进程已持有至少一个资源，同时等待其他进程释放额外资源。

   

   不可抢占（No Preemption）

   资源不能被强制从持有它的进程中剥夺，只能自愿释放。

   

   循环等待（Circular Wait）

   存在进程资源的环形等待链（如A→B→C→A）。

4. ##### 悲观锁与乐观锁的区别，就像“防贼”和“事后检查”两种生活态度：

   悲观锁（Pessimistic Lock）——出门必锁门
   核心思想：“总有人会改我的数据，先锁住再说！”
   工作方式：操作数据前先加锁（如行锁、表锁），确保独占访问。
   适用场景：
   写操作频繁，冲突概率高（如银行转账、库存扣减）。
   长事务或复杂业务逻辑（需长时间持有数据）。
   优点：保证强一致性，避免脏写。
   缺点：加锁时间长，降低并发性能（其他线程需等待）。

   乐观锁（Optimistic Lock）——回家再检查
   核心思想：“大家一般不会冲突，万一冲突了再处理！”
   工作方式：不加锁，提交时检查数据是否被修改（如版本号、时间戳）。
   适用场景：
   读多写少，冲突概率低（如文章点赞、配置更新）。

   ##### 高并发读场景（避免锁竞争拖慢系统）。

   1：电商秒杀
   悲观锁：用户点击秒杀时，直接锁库存 → 可能拖垮数据库。
   乐观锁：先放用户进入，提交订单时检查库存版本号 → 更适合高并发。
   场景2：文档协作编辑
   悲观锁：编辑前锁定文档 → 其他人无法同时修改，体验差。
   乐观锁：所有人自由编辑，保存时检查版本冲突 → 类似Google Docs。

   ##### 如何选择？

   选悲观锁：
   数据强一致性要求高（如金融系统）。
   写冲突频繁，重试成本高。
   选乐观锁：
   读多写少，冲突概率低。
   系统吞吐量要求高（如互联网应用）。

5. ##### 线程上下文切换是指：

   ##### 线程的上下文切换的是什么？当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

6. ##### 自旋锁

   自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。

   自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系。

   **自旋锁** 就像你在餐厅门口等位时，**一直盯着服务员问“有空位了吗？”**，而不是取个号去逛街。用大白话解释：

   ------

   ##### **自旋锁是啥？**

   - **核心逻辑**：线程在抢不到锁时，**死循环不停检查锁状态**，直到锁被释放。
   - 特点：
     - **不放弃CPU**：线程一直占着CPU，不睡觉（不进入阻塞状态）。
     - **适合短等待**：如果锁很快被释放，能立即抢到，响应快。

   ##### **自旋锁 vs 互斥锁（普通锁）**

   |   **场景**   |         **自旋锁**          |          **互斥锁**          |
   | :----------: | :-------------------------: | :--------------------------: |
   | **等锁方式** |   死循环问“锁释放了吗？”    | 取个号去睡觉，等锁释放被叫醒 |
   | **CPU占用**  |     高（一直占着CPU问）     |      低（睡觉不占CPU）       |
   | **适用场景** | 锁持有时间极短（如几纳秒）  | 锁持有时间长（如几毫秒以上） |
   | **典型应用** | 内核中断处理、多核CPU短任务 |     用户态程序、文件读写     |

   ------

   #####  举个栗子🌰——抢厕所

   - **自旋锁**：
     你急着上厕所，门锁着。你站在门口 **不停敲门**：“好了没？好了没？” → 里面的人一出来，你立刻冲进去。
     - **优点**：反应快，一开门就能抢到。
     - **缺点**：一直敲门累死自己（浪费体力/CPU）。
   - **互斥锁**：
     你发现厕所门锁着，**回工位刷手机**，等有人喊“厕所空了”再过去。
     - **优点**：省体力（不占CPU）。
     - **缺点**：可能错过第一时间（唤醒延迟）。

   ------

   ##### **自旋锁的适用场景**

   - **锁持有时间极短**：比如修改一个变量值、更新计数器。
   - **多核CPU环境**：一个核死循环等锁，其他核照常干活，不影响整体效率。
   - **不能睡眠的场景**：如操作系统内核的中断处理程序（中断时不能切换线程）。

   ------

   ##### **自旋锁的坑**

   - **单核CPU慎用**：如果锁一直被占用，自旋锁会 **100%占着CPU**，导致其他线程无法运行，永远拿不到锁（死锁）。
   - **长时间等待血亏**：自旋锁等1秒 → CPU空转1秒，不如让出CPU给其他任务。

7. ##### 加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。

   **锁** 就像现实生活中的 **“门锁”**，只不过它保护的不是房间，而是计算机中的 **共享资源（比如变量、文件、数据库记录）**，防止多个线程或进程同时修改导致数据混乱。

   - **本质**：一种同步工具，确保 **同一时间只有一个线程能访问共享资源**。
   - 类比：
     - 公共厕所只有一个坑位，进去的人锁门（加锁），出来解锁（释放锁），其他人才能用。
     - 多人编辑同一份文档，谁先打开就锁定文件，其他人只能等。

   ##### **避免结果不可预测**

   - 场景

     ：多人抢票系统，余票为1时，两个用户同时点击购买。

     - **不加锁**：可能两人都买到票，导致超卖。
     - **加锁**：第一个人锁定票数，第二个人需等待，确保余票正确扣减。

   ##### **锁的工作流程**

   1. 加锁：线程访问共享资源前，先申请锁。
      - 如果锁空闲 → 获得锁，进入临界区（需要保护的代码段）。
      - 如果锁被占用 → 等待（阻塞或自旋）。
   2. **操作资源**：在锁的保护下安全修改数据。
   3. **释放锁**：操作完成后释放锁，其他线程可竞争获取。

   ------

   ##### **锁的代价**

   - **性能开销**：加锁/解锁需要时间，高并发时可能成为瓶颈。
   - **死锁风险**：多个锁互相等待（如A等B，B等A）。
   - **设计复杂度**：锁粒度太粗（性能差）、太细（易出错）。

   ------

   ##### **常见锁的类型**

   |  **锁类型**  |     **特点**      |     **适用场景**     |
   | :----------: | :---------------: | :------------------: |
   |  **互斥锁**  | 阻塞等待，让出CPU |   大部分用户态程序   |
   |  **自旋锁**  | 忙等待，不释放CPU | 内核短操作、多核环境 |
   |  **读写锁**  |  读共享，写独占   |  读多写少（如缓存）  |
   | **条件变量** | 等待特定条件成立  |  生产者-消费者模型   |

   ------

   ##### **总结**

   - **锁是并发编程的“交通警察”**：确保共享资源有序访问。
   - 核心口诀：
     - 共享数据要保护，先加锁来后操作；

8. 开发过程中，最常见的就是互斥锁的了，互斥锁加锁失败时，会用「线程切换」来应对，当加锁失败的线程再次加锁成功后的这一过程，会有两次线程上下文切换的成本，性能损耗比较大。

   如果我们明确知道被锁住的代码的执行时间很短，那我们应该选择开销比较小的自旋锁，因为自旋锁加锁失败时，并不会主动产生线程切换，而是一直忙等待，直到获取到锁，那么如果被锁住的代码执行时间很短，那这个忙等待的时间相对应也很短。

   如果能区分读操作和写操作的场景，那读写锁就更合适了，它允许多个读线程可以同时持有读锁，提高了读的并发性。根据偏袒读方还是写方，可以分为读优先锁和写优先锁，读优先锁并发性很强，但是写线程会被饿死，而写优先锁会优先服务写线程，读线程也可能会被饿死，那为了避免饥饿的问题，于是就有了公平读写锁，它是用队列把请求锁的线程排队，并保证先入先出的原则来对线程加锁，这样便保证了某种线程不会被饿死，通用性也更好点。

   互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。

   另外，互斥锁、自旋锁、读写锁都属于悲观锁，悲观锁认为并发访问共享资源时，冲突概率可能非常高，所以在访问共享资源前，都需要先加锁。

   相反的，如果并发访问共享资源时，冲突概率非常低的话，就可以使用乐观锁，它的工作方式是，在访问共享资源时，不用先加锁，修改完共享资源后，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。

   但是，一旦冲突概率上升，就不适合使用乐观锁了，因为它解决冲突的重试成本非常高。

   不管使用的哪种锁，我们的加锁的代码范围应该尽可能的小，也就是加锁的粒度要小，这样执行速度会比较快。再来，使用上了合适的锁，就会快上加快了。

   ------

   ## 五、调度算法

   ### 进程调度/页面置换/磁盘调度算法

   ------

   ## 1、进程调度

   **进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。**
   
   **当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。**
   
   什么时候会发生 CPU 调度呢？通常有以下情况：
   
   1. 当进程从运行状态转到等待状态；
   
   2. 当进程从运行状态转到就绪状态；
   
   3. 当进程从等待状态转到就绪状态；
   
   4. 当进程从运行状态转到终止状态；
   
      其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。
   
      非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。
   
      而抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。
   
      你可能会好奇为什么第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。
   
      那第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。
   
   **调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。**
   
   **调度算法影响的是进程的等待时间，而无法改变进程实际需要的 CPU 时间和 I/O 时间。** 这句话可以拆解为以下核心点：
   
   ---
   
   ### **1. 什么是“等待时间”？**
   - **定义**：进程在 **就绪队列** 中等待被 CPU 调度的时间总和。  
   - **受调度算法影响**：不同算法决定了进程何时能获得 CPU 使用权。  
     - **例**：短作业优先（SJF）会让短进程少等待，长进程多等待；而先来先服务（FCFS）则按到达顺序排队，不管任务长短。
   
   ---
   
   ### **2. 什么是“进程真在使用 CPU 的时间”和“I/O 时间”？**
   - **CPU 时间**：进程 **实际执行代码** 所需的时间（如计算 1+1、排序数组）。  
     - **由程序逻辑决定**：无论调度算法如何，计算 1 亿次加法总需要固定的 CPU 时间。  
   - **I/O 时间**：进程 **等待外部设备** 的时间（如读取硬盘、网络请求）。  
     - **由硬件速度决定**：无论调度算法如何，从硬盘读 1GB 数据总需要固定的 I/O 时间。
   
   ---
   
   ### **3. 为什么调度算法无法影响 CPU 和 I/O 时间？**
   - **CPU 时间**：  
     - 程序需要执行多少条指令是固定的，调度算法只能决定 **何时分配 CPU**，但无法减少 **总指令数**。  
     - **例**：一个进程需要 10 秒 CPU 时间，无论是连续执行（FCFS）还是分片执行（RR），总时间都是 10 秒。
   
   - **I/O 时间**：  
     - I/O 操作的速度由硬件（如磁盘转速、网络带宽）决定，调度算法只能管理 **I/O 请求的顺序**，但无法加速设备响应。  
     - **例**：从 SSD 读取文件需要 0.1 秒，无论调度算法如何优化，这个时间无法缩短。
   
   ---
   
   ### **4. 调度算法的作用范围**
   | **调度算法能影响的**             | **调度算法不能影响的**         |
   | -------------------------------- | ------------------------------ |
   | 进程在就绪队列中的等待时间       | 进程实际需要的 CPU 时间        |
   | 进程获得 CPU 的顺序和频率        | 进程执行代码的速度（CPU 算力） |
   | 进程切换的开销（上下文切换次数） | I/O 设备的物理速度             |
   | 系统整体的吞吐量和响应时间       | 单个进程的 CPU 或 I/O 需求     |
   
   ---
   
   ### **5. 举个实际例子**
   假设有两个进程：  
   - **进程A**：需要 5 秒 CPU 时间（纯计算任务）。  
   - **进程B**：需要 2 秒 CPU 时间 + 3 秒 I/O 时间。  
   
   **不同调度算法的表现**：  
   - **FCFS（先来先服务）**：  
     - 若 A 先执行 → A 用 5 秒 CPU，B 等待 5 秒后执行 → B 总等待时间 = 5 秒。  
     - **总 CPU 时间**：A(5) + B(2) = 7 秒（不变）。  
     - **总 I/O 时间**：B(3) 秒（不变）。  
   
   - **SJF（短作业优先）**：  
     - 若 B 先执行 → B 用 2 秒 CPU，A 等待 2 秒后执行 → B 总等待时间 = 0 秒，A 总等待时间 = 2 秒。  
     - **总 CPU 时间**：A(5) + B(2) = 7 秒（不变）。  
     - **总 I/O 时间**：B(3) 秒（不变）。  
   
   → **调度算法改变了等待时间，但 CPU 和 I/O 时间始终不变**。
   
   ---
   
   ### **6. 总结**
   - **调度算法是“时间管理大师”**：决定进程何时运行、运行多久，优化等待时间和系统效率。  
   - **程序需求是“硬指标”**：CPU 和 I/O 时间由代码和硬件决定，调度算法无法压缩。  
   - **关键结论**：  
     - 你可以通过调度让任务更快开始，但无法让它更快完成（除非升级硬件或优化代码）。  
     - 想缩短任务总耗时？优化程序逻辑或换更快的硬件，而不是调整调度算法！  
   
   下次遇到性能瓶颈时，先分清是“等太久”还是“干太慢”——调度算法只管前者，不管后者。 ⏳🚀
   
   
   
   **进程调度算法** 就像银行柜员决定 **“下一个叫哪个号”** 的规则，目标是让客户（进程）高效办理业务（执行任务），同时兼顾公平性和响应速度。以下是常见调度算法的大白话解释：
   
   ---
   
   ### **1. 先来先服务（FCFS）——老实人排队**
   - **规则**：谁先来，谁先办，办完一个再下一个。  
   - **优点**：简单公平，不插队。  
   - **缺点**：  
     - **长任务卡死短任务**：比如第一个人办1小时业务，后面的人等崩溃。  
     - **平均等待时间长**：短任务被长任务拖累。  
   - **场景**：早期简单系统，现已少用。
   - FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。
   
   ---
   
   ### **2. 短作业优先（SJF）——VIP快速通道**
   - **规则**：柜员优先处理 **“办理时间最短”** 的业务。  
   - **优点**：平均等待时间最短，短任务爽翻天。  
   - **缺点**：  
     - **长任务饿死**：如果一直来短任务，长任务永远轮不到。  
     - **预知时间难**：现实中很难提前知道业务要办多久。  
   - **场景**：批处理系统（如后台计算任务）。
   - 比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。
   
   
   
   ### 小林：那么，高响应比优先
   
   （\*Highest Response Ratio Next, HRRN\*）调度算法**主要是权衡了短作业和长作业。
   
   
   
   #### **算法核心思想**
   
   - **响应比（Response Ratio）**：动态计算每个作业的优先级，优先调度 **响应比最高** 的作业。
   
     ![image-20250405164232312](img/image-20250405164232312.png)
   
     - **等待时间**：作业在就绪队列中等待的时间。
     - **预计运行时间**：作业需要的 CPU 时间（需提前预知）。
   
   - 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
   - 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；
   
   ---
   
   ### **3. 时间片轮转（RR）——每人限时办业务**
   - **规则**：每人最多办 **固定时间（时间片）**，超时就重新排队。  
     - 比如时间片=5分钟：A办5分钟 → B办5分钟 → C办5分钟 → 循环。  
     
   - **优点**：公平，响应快，适合交互式系统（如电脑桌面）。  
   
   - **缺点**：  
     - 时间片太短 → 频繁切换，效率低。  
     - 时间片太长 → 退化成FCFS，短任务等太久。  
     
   - **场景**：现代操作系统的默认调度策略。
   
     **每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。**
   
   - 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
   - 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；
   
   另外，时间片的长度就是一个很关键的点：
   
   - 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
   - 如果设得太长又可能引起对短作业进程的响应时间变长。将
   
   通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值
   
   ---
   
   ### **4. 优先级调度——看人下菜碟**
   - **规则**：给每个任务设优先级，柜员先处理优先级高的。  
     - **静态优先级**：优先级固定（如VIP客户永远优先）。  
     - **动态优先级**：优先级随时间变化（如等太久的任务自动升优先级）。  
   - **优点**：灵活，可处理紧急任务。  
   - **缺点**：  
     - **低优先级饿死**：高优先级任务源源不断，低优先级永远等不到。  
     - **优先级反转**：低优先级任务占着资源，高优先级干等（需额外机制解决）。  
   - **场景**：实时系统（如航天控制、工业自动化）。
   
   
   
   对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（\*Highest Priority First，HPF\*）调度算法**。
   
   进程的优先级可以分为，静态优先级或动态优先级：
   
   - 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
   - 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。
   
   该算法也有两种处理优先级高的方法，非抢占式和抢占式：
   
   - 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
   - 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。
   
   但是依然有缺点，可能会导致低优先级的进程永远不会运行。
   
   
   
   ---
   
   ### **5. 多级反馈队列（MLFQ）——智能分诊**
   
   **多级反馈队列（\*Multilevel Feedback Queue\*）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。
   
   - **规则**：  
     1. 设置多个优先级队列，新任务进最高级队列。  
     2. 每个队列时间片不同（高级队列时间片短，低级队列时间长）。  
     3. 任务用完时间片未完成 → 降级到下一队列。  
     4. 任务主动让出CPU（如等I/O） → 保持或升级队列。  
     5. 定期重置所有任务到最高队列 → 防饿死。  
   - **优点**：平衡响应时间和吞吐量，兼顾长短任务。  
   - **缺点**：参数调优复杂（队列数量、时间片大小等）。  
   - **场景**：通用操作系统（如Linux、Windows）。
   
   ![image-20250405164825068](img/image-20250405164825068.png)
   
   小林：它是如何工作的：
   
   - 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
   - **新的进程会被放入到第一级队列的末尾**，按**先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾**，以此类推，直至完成；
   - **当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行**；
   
   可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**
   
   ---
   
   ### **总结：如何选算法？**
   | **场景**           | **推荐算法**         | **原因**                   |
   | ------------------ | -------------------- | -------------------------- |
   | 服务器处理批量任务 | 短作业优先（SJF）    | 快速完成短任务，提升吞吐量 |
   | 个人电脑交互操作   | 时间片轮转（RR）     | 公平响应，避免卡顿         |
   | 实时控制系统       | 优先级调度           | 确保紧急任务优先执行       |
   | 通用多任务环境     | 多级反馈队列（MLFQ） | 自适应长短任务，平衡效率   |
   
   ---
   
   **口诀记忆**：  
   
   - 先来先服务老实人，短作业优先快狠准；  
   - 时间片轮转保公平，优先级调度看身份；  
   - 多级反馈最智能，通用系统它称王！  
   
   理解这些算法，就能明白操作系统如何“公平高效”地管理任务啦！ 🖥️⚖️
   
   
   
   ## 2、内存页面置换算法
   
   **当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断**，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：
   
   - 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。
   
   - 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。
   
   - **缺页中断的处理流程**：
   
     ![image-20250405170104127](img/image-20250405170104127.png)
   
   1. 在 CPU 里访问一条 **Load M 指令，然后 CPU 会去找 M 所对应的页表项。**
   
   2. 如果**该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。**
   
      ![image-20250405171428074](img/image-20250405171428074.png)
   
      **页表项的字段**：
   
      - *状态位*：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。
      - *访问字段*：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。
      - *修改位*：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。
      - *硬盘地址*：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。
   
   3. **操作系统收到了缺页中断，则会执行缺页中断处理函数**，先会查找该页面在磁盘中的页面的位置。
   
   4. **找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。**
   
   5. 页面**从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」**。
   
   6. 最后，**CPU 重新执行导致缺页异常的指令。**
   
   上面所说的过程，第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？
   
   **找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。**
   
   （在内存页面置换算法中提到的 **「磁盘」和「内存」** 具体含义：
   
   ### **磁盘（Disk）**
   
   - **指代**：操作系统的 **交换空间（Swap Space）**，通常位于硬盘上。
   - 作用：
     - 当物理内存不足时，临时存储被换出的内存页面。
     - 保存未被修改的页面副本（如代码段、只读数据），或脏页（被修改过的数据页）的最终版本。
   - **类比**：像一个「备用仓库」，存放暂时不用的物品（页面），需要时再取回。
   
   ###  **内存（Memory）**
   
   - **指代**：**物理内存（Physical Memory / RAM）**，即计算机的实际内存条。
   
   - 作用
   
     ：
   
     - 存放当前正在运行的进程所需的页面（代码、数据、堆栈等）。
     - CPU 直接访问物理内存中的页面，速度远快于磁盘。
   
   - **类比**：像「书桌」，存放你正在使用的书籍和工具（页面），空间有限。
   
   ### **页面置换算法中的「置换」是什么？**
   
   - 置换目标
   
     ：
   
     - **物理内存中的页面** → 当物理内存已满时，选择一个页面换出到磁盘（Swap Out）。
     - **磁盘中的页面** → 当需要访问不在物理内存中的页面时，将其换入内存（Swap In）。
   
   - 关键点
   
     ：
   
     - 置换的是 **物理内存和磁盘之间的页面**，而非 CPU 缓存或其他内存层级。
     - 若被换出的页面是「脏页」（被修改过），需先写回磁盘；否则直接丢弃（磁盘已有副本）。
   
   ）
   
   ### **为什么需要页面置换？**
   
   - **物理内存有限**：无法同时加载所有进程的页面。
   - **局部性原理**：程序运行时只需部分页面在内存中，其余可暂存磁盘。
   - **效率平衡**：通过置换算法，让最常用的页面留在内存，减少访问磁盘的昂贵开销。
   
   **类比**：
   
   - 物理内存 = 你的书桌（空间有限，放正在用的书）。
   - 磁盘 = 书架（空间大，存放暂时不用的书）。
   - 页面置换 = 把书桌上的某本书放回书架，腾出空间放新书。
   
   理解这一点，就能明白页面置换算法如何优化内存使用，避免系统因内存不足而崩溃！ 🖥️📚
   
   页面置换算法的功能是，**当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。
   
   那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种：
   
   - 最佳页面置换算法（*OPT*）
   - 先进先出置换算法（*FIFO*）
   - 最近最久未使用的置换算法（*LRU*）
   - 时钟页面置换算法（*Lock*）
   - 最不常用置换算法（*LFU*）
   
   **内存页面置换算法** 是操作系统中用于管理虚拟内存的关键机制，当物理内存不足时，决定哪些页面应被换出到磁盘，以腾出空间加载新页面。以下是常见算法的详细说明：
   
   ---
   
   ### **一、最佳置换算法（OPT, Optimal Page Replacement）**
   - **原理**：淘汰 **未来最长时间不再被访问** 的页面（理论最优，但无法实现）。  
   - **优点**：缺页率最低，作为其他算法的性能基准。  
   - **缺点**：需预知未来页面访问序列，实际不可行。  
   - **示例**：  
     访问序列：`2, 3, 2, 1, 5, 2, 4, 5, 3`，物理内存3页。  
     - 当需置换时，选择未来最晚出现的页面（如页面1）。  
   
   基本思路是，**置换在「未来」最长时间不访问的页面**。
   
   其核心思想是 **淘汰未来最长时间不再被访问的页面**，从而最小化缺页次数。虽然实际中无法实现（需预知未来访问序列），但它为其他算法提供了性能上限的参考。以下通过一个具体例子详细说明：
   
   ### **示例场景**
   
   - **物理内存页框数**：3
   
   **物理内存页框数** 是操作系统中内存管理的重要概念，它直接决定了系统能同时容纳多少页面，进而影响程序的运行效率和稳定性。
   
   - **定义**：
     物理内存被划分为多个 **固定大小的块**（如4KB），每个块称为一个 **页框（Page Frame）**。
     - **类比**：像书架上的格子，每个格子大小相同，用来放书（页面）。
   - **页框数**：
     物理内存中页框的总数量。例如：
     - 若物理内存 **4GB**，页框大小 **4KB** → 页框数 = 4GB / 4KB = **1,048,576个**。
   
   - **物理内存页框数 = 内存的“格子数量”**，决定了能同时存放多少数据。
   
   - **页框越多** → 系统越流畅，多任务处理能力越强。
   
   - **页框不足** → 频繁换页拖慢速度，甚至引发崩溃。
   
     
   
   - **页面访问序列**：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`
   - **目标**：展示 OPT 如何选择置换页面。
   
   ------
   
   ### **分步解析**
   
   | **访问页面** | **物理内存状态** | **是否缺页** | **置换选择（若缺页）** |                         **选择理由**                         |
   | :----------: | :--------------: | :----------: | :--------------------: | :----------------------------------------------------------: |
   |      1       |       [1]        |  是（首次）  |           -            |                     内存为空，直接加载。                     |
   |      2       |      [1, 2]      |      是      |           -            |                     内存未满，继续加载。                     |
   |      3       |    [1, 2, 3]     |      是      |           -            |                     内存未满，继续加载。                     |
   |      4       |    [1, 2, 4]     |      是      |     **淘汰页面3**      | 未来访问序列中，页面3的下次访问在第10步，而页面1和2会更早被访问（第5、6步）。 |
   |      1       |    [1, 2, 4]     |      否      |           -            |                       页面1已在内存。                        |
   |      2       |    [1, 2, 4]     |      否      |           -            |                       页面2已在内存。                        |
   |      5       |    [1, 2, 5]     |      是      |     **淘汰页面4**      | 页面4的下次访问在第11步，页面1和2会更早被访问（第8、9步）。  |
   |      1       |    [1, 2, 5]     |      否      |           -            |                       页面1已在内存。                        |
   |      2       |    [1, 2, 5]     |      否      |           -            |                       页面2已在内存。                        |
   |      3       |    [3, 2, 5]     |      是      |     **淘汰页面1**      |   页面1未来不再被访问，页面2和5的下次访问更晚（第12步）。    |
   |      4       |    [3, 4, 5]     |      是      |     **淘汰页面2**      |        页面2未来不再被访问，页面5的下次访问在第12步。        |
   |      5       |    [3, 4, 5]     |      否      |           -            |                       页面5已在内存。                        |
   
   ------
   
   ### **关键点总结**
   
   1. **置换策略**：
      - 每次缺页时，OPT 会淘汰 **未来最晚被访问** 或 **不再被访问** 的页面。
      - 例如，在第4步访问页面4时，内存已满，需在页面1、2、3中选择淘汰：
        - 页面1将在第5步被访问，页面2在第6步，页面3在第10步。
        - 页面3是未来最晚被访问的 → 淘汰页面3。
   2. **缺页次数统计**：
      - 总缺页次数 = **7次**（访问序列中加粗的步骤）。
      - 对比其他算法：
        - FIFO：9次缺页
        - LRU：7次缺页（与OPT相同，但本例中巧合）
        - Clock：8次缺页
   3. **OPT 的局限性**：
      - **需预知未来访问序列**：实际系统中无法实现，仅作为理论基准。
      - **动态性不足**：无法应对实时变化的访问模式（如程序行为突变）。
   
   这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。
   
   所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。
   
   **总结**：
   
   - OPT 是页面置换的“理想模型”，通过预知未来达到最优性能。
   - 实际系统中，LRU 和 Clock 算法通过近似 OPT 的行为，提供接近最优的性能。
   - 理解 OPT 有助于评估其他算法的优劣，例如 LRU 的缺页率越接近 OPT，说明其设计越高效。
   
   ---
   
   ### **二、先进先出算法（FIFO, First-In-First-Out）**
   
   可以**选择在内存驻留时间很长的页面进行中置换**，这个就是「先进先出置换」算法的思想。
   
   - **原理**：淘汰 **最早进入内存** 的页面。  
   - **实现**：维护一个队列，新页面加入队尾，置换时移除队首页面。  
   - **优点**：实现简单。  
   - **缺点**：  
     
     - **Belady 异常**：增加物理页框数时，缺页率可能不降反升。  
     - 忽略页面访问频率，可能淘汰常用页面。  
   - **示例**：  
     访问序列：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`，物理内存3页。  
     
     - 缺页次数：9次（FIFO） vs 7次（LRU）。  
     
     ### **FIFO 的核心规则**
     
     1. **队列管理**：所有页面按 **进入内存的时间顺序** 排成一个队列。
     2. **置换策略**：当需要置换页面时，选择 **最早进入内存的页面**（即队列头部的页面）。
     3. **新页面处理**：新加载的页面加入队列尾部。
     
     ------
     
     ### **二、示例场景**
     
     - **物理内存页框数**：3
     - **页面访问序列**：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`
     - **目标**：展示 FIFO 如何选择置换页面，并统计缺页次数。
     
     ------
     
     ### **三、分步解析**
     
     | **访问页面** | **物理内存状态** | **是否缺页** | **置换选择（若缺页）** | **队列状态（进入顺序）** |
     | :----------: | :--------------: | :----------: | :--------------------: | :----------------------: |
     |      1       |       [1]        |  是（首次）  |           -            |           [1]            |
     |      2       |      [1, 2]      |      是      |           -            |          [1, 2]          |
     |      3       |    [1, 2, 3]     |      是      |           -            |        [1, 2, 3]         |
     |      4       |    [2, 3, 4]     |      是      |     **淘汰页面1**      |        [2, 3, 4]         |
     |      1       |    [3, 4, 1]     |      是      |     **淘汰页面2**      |        [3, 4, 1]         |
     |      2       |    [4, 1, 2]     |      是      |     **淘汰页面3**      |        [4, 1, 2]         |
     |      5       |    [1, 2, 5]     |      是      |     **淘汰页面4**      |        [1, 2, 5]         |
     |      1       |    [1, 2, 5]     |      否      |           -            |        [1, 2, 5]         |
     |      2       |    [1, 2, 5]     |      否      |           -            |        [1, 2, 5]         |
     |      3       |    [2, 5, 3]     |      是      |     **淘汰页面1**      |        [2, 5, 3]         |
     |      4       |    [5, 3, 4]     |      是      |     **淘汰页面2**      |        [5, 3, 4]         |
     |      5       |    [5, 3, 4]     |      否      |           -            |        [5, 3, 4]         |
     
     ------
     
     ### **四、关键点总结**
     
     1. **缺页次数**：共 **9次缺页**（标为“是”的步骤）。
     
     2. Belady 异常（Belady Anomaly）
     
        ：
     
        - **现象**：增加物理内存页框数时，缺页率可能不降反升。
        - **示例**：若物理内存页框数从3增加到4，对某些访问序列，FIFO的缺页次数反而增加。
     
     3. 问题根源
     
        ：
     
        - FIFO 仅根据进入时间淘汰页面，**完全忽略页面的访问频率**。
        - 可能淘汰高频访问的页面（如页面1和2被反复淘汰并重新加载）。
   
   ---
   
   ### **三、最近最少使用算法（LRU, Least Recently Used）**
   
   发生缺页时，**选择最长时间没有被访问的页面进行置换**，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。
   
   这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。
   
   - **原理**：淘汰 **最长时间未被访问** 的页面。  
   - **实现**：  
     - **计数器/时间戳**：记录每个页面最后一次访问时间。  
     - **链表**：每次访问页面时将其移到链表头部，淘汰尾部页面。  
   - **优点**：接近OPT性能，缺页率低。  
   - **缺点**：硬件实现复杂（需记录访问时间）。  
   - **示例**：  
     访问序列：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`，物理内存3页。  
     - 缺页次数：7次。  
   
   **最近最久未使用置换算法（LRU，Least Recently Used）** 是一种基于页面访问历史的置换策略，其核心思想是 **淘汰最长时间未被访问的页面**，以利用程序的局部性原理，减少缺页率。以下是详细说明和示例：
   
   ------
   
   ### **一、LRU 的核心原理**
   
   - **时间局部性**：如果一个页面最近被访问过，它很可能在不久的将来再次被访问。
   - **淘汰策略**：选择 **最久未被访问的页面** 进行置换，保留近期可能被使用的页面。
   
   ------
   
   ### **二、LRU 的实现方式**
   
   #### **1. 链表法**
   
   - **维护链表**：所有页面按访问时间排序，最近访问的页面在链表头部，最久未访问的在尾部。
   
   - 操作
   
     ：
   
     - **访问页面**：若页面在链表中，将其移到头部；若不在，加载到头部并淘汰尾部页面。
     - **置换页面**：直接淘汰链表尾部页面。
   
   #### **2. 计数器/时间戳法**
   
   - **记录时间戳**：每个页面维护一个最后访问时间戳。
   - **置换时**：选择时间戳最早的页面淘汰。
   
   #### **3. 近似实现（Clock 算法）**
   
   - **访问位（R位）**：页面被访问时置1，定期扫描并清零。
   - **置换策略**：类似时钟算法，但结合访问历史近似LRU。
   
   ------
   
   ### **三、LRU 示例分析**
   
   - **物理内存页框数**：3
   - **页面访问序列**：`1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5`
   - **目标**：统计缺页次数并展示置换过程。
   
   ------
   
   #### **分步解析**
   
   | **访问页面** | **物理内存状态** | **是否缺页** | **置换选择（若缺页）** | **访问顺序（最近→最久）** |
   | :----------: | :--------------: | :----------: | :--------------------: | :-----------------------: |
   |      1       |       [1]        |  是（首次）  |           -            |            [1]            |
   |      2       |      [1, 2]      |      是      |           -            |          [2, 1]           |
   |      3       |    [1, 2, 3]     |      是      |           -            |         [3, 2, 1]         |
   |      4       |    [2, 3, 4]     |      是      |     **淘汰页面1**      |         [4, 3, 2]         |
   |      1       |    [3, 4, 1]     |      是      |     **淘汰页面2**      |         [1, 4, 3]         |
   |      2       |    [4, 1, 2]     |      是      |     **淘汰页面3**      |         [2, 1, 4]         |
   |      5       |    [1, 2, 5]     |      是      |     **淘汰页面4**      |         [5, 2, 1]         |
   |      1       |    [5, 2, 1]     |      否      |           -            |         [1, 5, 2]         |
   |      2       |    [5, 1, 2]     |      否      |           -            |         [2, 1, 5]         |
   |      3       |    [1, 2, 3]     |      是      |     **淘汰页面5**      |         [3, 2, 1]         |
   |      4       |    [2, 3, 4]     |      是      |     **淘汰页面1**      |         [4, 3, 2]         |
   |      5       |    [3, 4, 5]     |      是      |     **淘汰页面2**      |         [5, 4, 3]         |
   
   ------
   
   ### **四、关键点总结**
   
   1. **缺页次数**：共 **9次缺页**（标为“是”的步骤）。
   
   2. 性能对比
   
      ：
   
      - **OPT 算法**：7次缺页（理论最优）。
      - **FIFO 算法**：9次缺页（与LRU相同，但本例中因访问模式特殊）。
   
   3. **局部性失效**：本例中页面访问模式（如循环访问）导致LRU表现不佳，实际场景中LRU通常优于FIFO。
   
   - **LRU 是“以史为鉴”的置换策略**：通过淘汰最久未使用的页面，优化内存利用率。
   - **核心优势**：利用时间局部性，减少高频页面的置换次数。
   - **局限**：实现复杂，对特定访问模式（如循环）效果不佳。
   
   ---
   
   ### **四、时钟算法（Clock / Second Chance）**
   - **原理**：近似LRU，通过 **环形链表** 和 **访问位（R位）** 管理页面。  
   - **步骤**：  
     1. 页面组织成环形链表，初始访问位R=0。  
     2. 访问页面时，R=1。  
     3. 置换时，指针循环扫描：  
        - 若R=1 → 置R=0，跳过；  
        - 若R=0 → 淘汰该页。  
   - **优点**：开销低，接近LRU性能。  
   - **缺点**：可能淘汰最近使用但R位被清零的页面。  
   - **示例**：  
     访问序列：`1, 2, 3, 4, 1, 2, 5`，物理内存3页。  
     - 缺页次数：5次。  
   
   ---
   
   ### **五、最不常用算法（LFU, Least Frequently Used）**
   
   #### 最不常用算法
   
   最不常用（*LFU*）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰**。
   
   它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。
   
   看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。
   
   要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。
   
   但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。
   
   那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。
   
   
   
   - **原理**：淘汰 **访问次数最少** 的页面。  
   - **实现**：为每个页面维护访问计数器，置换时选择计数最小的页面。  
   - **优点**：适合访问模式稳定的场景。  
   - **缺点**：  
     - 历史累计访问次数可能掩盖近期变化。  
     - 计数器溢出问题。  
   - **变种**：**老化算法（Aging）**，定期右移计数器并叠加新访问位。  
   
   
   
   **最不常用算法（LFU，Least Frequently Used）** 是一种基于页面访问频率的置换算法，其核心思想是 **淘汰访问次数最少的页面**，适用于访问模式相对稳定的场景。以下是详细解析：
   
   ------
   
   ### **一、LFU 的核心原理**
   
   - **频率统计**：为每个页面维护一个 **访问计数器**，记录其被访问的次数。
   - **置换策略**：当需要置换页面时，选择 **访问次数最少** 的页面淘汰。
   - **平局处理**：若多个页面访问次数相同，可结合LRU策略（淘汰最久未访问的）。
   
   ------
   
   ### **二、LFU 的实现方式**
   
   #### **1. 基础实现（计数器法）**
   
   - **计数器更新**：每次页面被访问时，计数器加1。
   - **置换选择**：遍历所有页面，选择计数器值最小的页面淘汰。
   - **问题**：历史累计访问次数可能掩盖近期变化（如旧页面计数高但不再使用）。
   
   #### **2. 老化算法（Aging）**
   
   - **定期衰减**：每隔一段时间，将所有页面的计数器右移一位（相当于除以2）。
   - **新访问叠加**：每次访问时，计数器最高位设为1。
   - **优点**：减少历史数据影响，更关注近期访问模式。
   
   #### **3. 基于时间窗口的LFU**
   
   - **滑动窗口**：仅统计最近一段时间内的访问次数（如过去5分钟）。
   - **实现**：使用队列或环形缓冲区记录时间窗口内的访问事件。
   - **优点**：动态适应访问模式变化。
   
   ------
   
   ### **三、LFU 示例分析**
   
   - **物理内存页框数**：3
   - **页面访问序列**：`1, 2, 1, 3, 1, 2, 4, 3, 5`
   - **目标**：统计缺页次数并展示置换过程。
   
   ------
   
   #### **分步解析**
   
   | **访问页面** | **物理内存状态** | **访问计数器** | **是否缺页** |          **置换选择（若缺页）**           |
   | :----------: | :--------------: | :------------: | :----------: | :---------------------------------------: |
   |      1       |       [1]        |      1:1       |  是（首次）  |                     -                     |
   |      2       |      [1, 2]      |    1:1, 2:1    |      是      |                     -                     |
   |      1       |      [1, 2]      |    1:2, 2:1    |      否      |                     -                     |
   |      3       |    [1, 2, 3]     | 1:2, 2:1, 3:1  |      是      |                     -                     |
   |      1       |    [1, 2, 3]     | 1:3, 2:1, 3:1  |      否      |                     -                     |
   |      2       |    [1, 2, 3]     | 1:3, 2:2, 3:1  |      否      |                     -                     |
   |      4       |    [1, 2, 4]     | 1:3, 2:2, 4:1  |      是      |          **淘汰页面3**（计数1）           |
   |      3       |    [2, 4, 3]     | 2:2, 4:1, 3:1  |      是      | **淘汰页面4或3**（平局时选最久未访问的4） |
   |      5       |    [2, 3, 5]     | 2:2, 3:1, 5:1  |      是      | **淘汰页面3或5**（平局时选最久未访问的3） |
   
   ------
   
   ### **四、LFU 的优缺点**
   
   |                     **优点**                     |                     **缺点**                     |
   | :----------------------------------------------: | :----------------------------------------------: |
   |  ✅ **适合稳定访问模式**：长期热点数据保留率高。  | ❌ **历史累计问题**：旧页面计数高但可能不再使用。 |
   |      ✅ **减少高频页面置换**：保护常用数据。      |     ❌ **实现复杂**：需维护计数器和处理平局。     |
   | ✅ **无Belady异常**：增加内存页框数总能减少缺页。 |  ❌ **对突发访问不敏感**：新页面可能被快速淘汰。  |
   
   ---
   
   ### **六、算法对比与总结**
   | **算法**  | **实现复杂度** | **缺页率** | **硬件支持**  | **适用场景**            |
   | --------- | -------------- | ---------- | ------------- | ----------------------- |
   | **OPT**   | 理论不可实现   | 最低       | 无            | 性能基准                |
   | **FIFO**  | 简单           | 高         | 无            | 简单系统                |
   | **LRU**   | 高             | 低         | 需要（如TLB） | 通用系统                |
   | **Clock** | 中             | 中低       | 需要R位       | 实际操作系统（如Linux） |
   | **LFU**   | 高             | 中         | 需要计数器    | 特定访问模式            |
   
   ---
   
   ### **七、如何选择页面置换算法？**
   1. **追求性能**：LRU或Clock（平衡开销与效率）。  
   2. **硬件支持有限**：Clock算法（仅需访问位）。  
   3. **简单系统**：FIFO（易实现，但需注意Belady异常）。  
   4. **特定访问模式**：LFU（如缓存热点数据）。  
   
   ---
   
   **口诀**：  
   - OPT理论最优，FIFO简单但有坑；  
   - LRU效果好，实现成本高；  
   - Clock折中选，实际系统最爱用！  
   
   理解这些算法，有助于优化内存管理，提升系统整体性能。 🖥️⚡



## 3、磁盘调度算法

